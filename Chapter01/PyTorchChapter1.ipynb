{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrLt-C4PRV_f",
    "outputId": "93b5119e-505d-4ab5-a3bb-26803d9b517f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu130\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce GTX 1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/5A60AFFC60AFDCCF/PyCode/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1070 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.5) - (12.0)\n",
      "    \n",
      "  queued_call()\n",
      "/mnt/5A60AFFC60AFDCCF/PyCode/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  queued_call()\n",
      "/mnt/5A60AFFC60AFDCCF/PyCode/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "NVIDIA GeForce GTX 1070 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_75 sm_80 sm_86 sm_90 sm_100 sm_120 compute_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  queued_call()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It4yTLaRao7o",
    "outputId": "896ad986-b4bd-4376-ef3d-9575aa9cd807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 8.310893058776855\n",
      "Loss = 7.096347808837891\n",
      "Loss = 6.1293463706970215\n",
      "Loss = 5.357335567474365\n",
      "Loss = 4.738962650299072\n",
      "Loss = 4.24169397354126\n",
      "Loss = 3.8399219512939453\n",
      "Loss = 3.5135011672973633\n",
      "Loss = 3.2465732097625732\n",
      "Loss = 3.026660203933716\n",
      "Loss = 2.843939781188965\n",
      "Loss = 2.6906802654266357\n",
      "Loss = 2.560792922973633\n",
      "Loss = 2.449486494064331\n",
      "Loss = 2.3529856204986572\n",
      "Loss = 2.2683160305023193\n",
      "Loss = 2.193134069442749\n",
      "Loss = 2.125593662261963\n",
      "Loss = 2.0642364025115967\n",
      "Loss = 2.007913827896118\n",
      "Loss = 1.9557167291641235\n",
      "Loss = 1.906927227973938\n",
      "Loss = 1.8609780073165894\n",
      "Loss = 1.8174184560775757\n",
      "Loss = 1.775890827178955\n",
      "Loss = 1.7361111640930176\n",
      "Loss = 1.6978527307510376\n",
      "Loss = 1.6609339714050293\n",
      "Loss = 1.6252096891403198\n",
      "Loss = 1.5905617475509644\n",
      "Loss = 1.5568957328796387\n",
      "Loss = 1.5241328477859497\n",
      "Loss = 1.4922103881835938\n",
      "Loss = 1.4610748291015625\n",
      "Loss = 1.4306820631027222\n",
      "Loss = 1.400995135307312\n",
      "Loss = 1.3719817399978638\n",
      "Loss = 1.343614935874939\n",
      "Loss = 1.315869927406311\n",
      "Loss = 1.2887262105941772\n",
      "Loss = 1.2621647119522095\n",
      "Loss = 1.2361677885055542\n",
      "Loss = 1.210720181465149\n",
      "Loss = 1.1858073472976685\n",
      "Loss = 1.161415457725525\n",
      "Loss = 1.1375319957733154\n",
      "Loss = 1.114145040512085\n",
      "Loss = 1.0912429094314575\n",
      "Loss = 1.0688148736953735\n",
      "Loss = 1.046850323677063\n",
      "Loss = 1.0253390073776245\n",
      "Loss = 1.0042716264724731\n",
      "Loss = 0.9836382269859314\n",
      "Loss = 0.9634296298027039\n",
      "Loss = 0.943636953830719\n",
      "Loss = 0.9242517352104187\n",
      "Loss = 0.9052650332450867\n",
      "Loss = 0.8866687417030334\n",
      "Loss = 0.8684549331665039\n",
      "Loss = 0.8506153225898743\n",
      "Loss = 0.8331423401832581\n",
      "Loss = 0.8160285353660583\n",
      "Loss = 0.7992663383483887\n",
      "Loss = 0.7828486561775208\n",
      "Loss = 0.7667681574821472\n",
      "Loss = 0.7510180473327637\n",
      "Loss = 0.735591471195221\n",
      "Loss = 0.7204819321632385\n",
      "Loss = 0.7056825757026672\n",
      "Loss = 0.6911873817443848\n",
      "Loss = 0.6769897937774658\n",
      "Loss = 0.6630840301513672\n",
      "Loss = 0.6494638323783875\n",
      "Loss = 0.6361234784126282\n",
      "Loss = 0.623056948184967\n",
      "Loss = 0.6102589964866638\n",
      "Loss = 0.5977240204811096\n",
      "Loss = 0.585446298122406\n",
      "Loss = 0.5734208822250366\n",
      "Loss = 0.5616424083709717\n",
      "Loss = 0.5501059889793396\n",
      "Loss = 0.5388063788414001\n",
      "Loss = 0.5277389883995056\n",
      "Loss = 0.5168989300727844\n",
      "Loss = 0.5062814354896545\n",
      "Loss = 0.49588218331336975\n",
      "Loss = 0.4856964647769928\n",
      "Loss = 0.47571995854377747\n",
      "Loss = 0.4659483730792999\n",
      "Loss = 0.45637747645378113\n",
      "Loss = 0.44700324535369873\n",
      "Loss = 0.43782147765159607\n",
      "Loss = 0.4288283586502075\n",
      "Loss = 0.4200199544429779\n",
      "Loss = 0.4113924503326416\n",
      "Loss = 0.4029421806335449\n",
      "Loss = 0.39466559886932373\n",
      "Loss = 0.38655886054039\n",
      "Loss = 0.3786187469959259\n",
      "Loss = 0.37084171175956726\n",
      "Loss = 0.3632242977619171\n",
      "Loss = 0.3557635247707367\n",
      "Loss = 0.34845587611198425\n",
      "Loss = 0.3412984311580658\n",
      "Loss = 0.33428797125816345\n",
      "Loss = 0.3274214565753937\n",
      "Loss = 0.32069602608680725\n",
      "Loss = 0.3141087591648102\n",
      "Loss = 0.3076566755771637\n",
      "Loss = 0.30133724212646484\n",
      "Loss = 0.295147567987442\n",
      "Loss = 0.2890850901603699\n",
      "Loss = 0.28314706683158875\n",
      "Loss = 0.27733102440834045\n",
      "Loss = 0.2716345191001892\n",
      "Loss = 0.2660549581050873\n",
      "Loss = 0.2605900466442108\n",
      "Loss = 0.2552373707294464\n",
      "Loss = 0.2499946504831314\n",
      "Loss = 0.24485962092876434\n",
      "Loss = 0.23983009159564972\n",
      "Loss = 0.23490379750728607\n",
      "Loss = 0.23007871210575104\n",
      "Loss = 0.2253527194261551\n",
      "Loss = 0.22072380781173706\n",
      "Loss = 0.21619002521038055\n",
      "Loss = 0.2117493599653244\n",
      "Loss = 0.20739991962909698\n",
      "Loss = 0.20313982665538788\n",
      "Loss = 0.19896720349788666\n",
      "Loss = 0.19488024711608887\n",
      "Loss = 0.1908772587776184\n",
      "Loss = 0.18695656955242157\n",
      "Loss = 0.1831163614988327\n",
      "Loss = 0.17935508489608765\n",
      "Loss = 0.17567099630832672\n",
      "Loss = 0.17206262052059174\n",
      "Loss = 0.16852830350399017\n",
      "Loss = 0.1650666445493698\n",
      "Loss = 0.16167612373828888\n",
      "Loss = 0.15835516154766083\n",
      "Loss = 0.1551024615764618\n",
      "Loss = 0.1519165188074112\n",
      "Loss = 0.14879611134529114\n",
      "Loss = 0.14573974907398224\n",
      "Loss = 0.14274613559246063\n",
      "Loss = 0.13981403410434723\n",
      "Loss = 0.13694217801094055\n",
      "Loss = 0.1341293305158615\n",
      "Loss = 0.13137419521808624\n",
      "Loss = 0.12867571413516998\n",
      "Loss = 0.12603265047073364\n",
      "Loss = 0.1234438419342041\n",
      "Loss = 0.12090826034545898\n",
      "Loss = 0.11842471361160278\n",
      "Loss = 0.11599218100309372\n",
      "Loss = 0.11360961198806763\n",
      "Loss = 0.11127600818872452\n",
      "Loss = 0.10899034142494202\n",
      "Loss = 0.10675162076950073\n",
      "Loss = 0.10455887764692307\n",
      "Loss = 0.10241111367940903\n",
      "Loss = 0.10030754655599594\n",
      "Loss = 0.09824716299772263\n",
      "Loss = 0.09622909873723984\n",
      "Loss = 0.09425250440835953\n",
      "Loss = 0.09231651574373245\n",
      "Loss = 0.09042025357484818\n",
      "Loss = 0.0885629951953888\n",
      "Loss = 0.08674386143684387\n",
      "Loss = 0.08496203273534775\n",
      "Loss = 0.08321691304445267\n",
      "Loss = 0.08150754868984222\n",
      "Loss = 0.07983336597681046\n",
      "Loss = 0.0781935453414917\n",
      "Loss = 0.07658738642930984\n",
      "Loss = 0.07501421868801117\n",
      "Loss = 0.07347341626882553\n",
      "Loss = 0.07196419686079025\n",
      "Loss = 0.07048603147268295\n",
      "Loss = 0.06903821974992752\n",
      "Loss = 0.06762012839317322\n",
      "Loss = 0.0662311390042305\n",
      "Loss = 0.06487070769071579\n",
      "Loss = 0.06353821605443954\n",
      "Loss = 0.06223310902714729\n",
      "Loss = 0.06095482409000397\n",
      "Loss = 0.05970277264714241\n",
      "Loss = 0.058476466685533524\n",
      "Loss = 0.057275280356407166\n",
      "Loss = 0.0560988187789917\n",
      "Loss = 0.05494653806090355\n",
      "Loss = 0.053817879408597946\n",
      "Loss = 0.05271245911717415\n",
      "Loss = 0.0516296923160553\n",
      "Loss = 0.05056919530034065\n",
      "Loss = 0.04953046515583992\n",
      "Loss = 0.04851308465003967\n",
      "Loss = 0.04751656576991081\n",
      "Loss = 0.04654054716229439\n",
      "Loss = 0.045584578067064285\n",
      "Loss = 0.04464823007583618\n",
      "Loss = 0.04373114928603172\n",
      "Loss = 0.04283289611339569\n",
      "Loss = 0.04195307195186615\n",
      "Loss = 0.04109134152531624\n",
      "Loss = 0.04024726524949074\n",
      "Loss = 0.03942054882645607\n",
      "Loss = 0.038610853254795074\n",
      "Loss = 0.037817731499671936\n",
      "Loss = 0.03704094514250755\n",
      "Loss = 0.03628012165427208\n",
      "Loss = 0.03553488478064537\n",
      "Loss = 0.034804973751306534\n",
      "Loss = 0.0340900793671608\n",
      "Loss = 0.03338981792330742\n",
      "Loss = 0.03270399197936058\n",
      "Loss = 0.03203224763274193\n",
      "Loss = 0.03137429431080818\n",
      "Loss = 0.030729832127690315\n",
      "Loss = 0.030098626390099525\n",
      "Loss = 0.02948039025068283\n",
      "Loss = 0.028874846175312996\n",
      "Loss = 0.028281748294830322\n",
      "Loss = 0.027700813487172127\n",
      "Loss = 0.027131816372275352\n",
      "Loss = 0.02657451294362545\n",
      "Loss = 0.026028649881482124\n",
      "Loss = 0.025494009256362915\n",
      "Loss = 0.024970345199108124\n",
      "Loss = 0.02445743978023529\n",
      "Loss = 0.02395506389439106\n",
      "Loss = 0.02346300520002842\n",
      "Loss = 0.02298106998205185\n",
      "Loss = 0.02250901609659195\n",
      "Loss = 0.02204667031764984\n",
      "Loss = 0.021593810990452766\n",
      "Loss = 0.021150270476937294\n",
      "Loss = 0.02071583829820156\n",
      "Loss = 0.0202903151512146\n",
      "Loss = 0.01987353526055813\n",
      "Loss = 0.019465316087007523\n",
      "Loss = 0.019065512344241142\n",
      "Loss = 0.01867387816309929\n",
      "Loss = 0.018290307372808456\n",
      "Loss = 0.01791461929678917\n",
      "Loss = 0.017546633258461952\n",
      "Loss = 0.017186230048537254\n",
      "Loss = 0.016833210363984108\n",
      "Loss = 0.016487451270222664\n",
      "Loss = 0.016148781403899193\n",
      "Loss = 0.015817081555724144\n",
      "Loss = 0.015492181293666363\n",
      "Loss = 0.015173960477113724\n",
      "Loss = 0.01486229244619608\n",
      "Loss = 0.014556989073753357\n",
      "Loss = 0.014258000068366528\n",
      "Loss = 0.013965130783617496\n",
      "Loss = 0.013678266666829586\n",
      "Loss = 0.013397306203842163\n",
      "Loss = 0.0131221367046237\n",
      "Loss = 0.012852598913013935\n",
      "Loss = 0.012588594108819962\n",
      "Loss = 0.0123300114646554\n",
      "Loss = 0.012076751329004765\n",
      "Loss = 0.011828676797449589\n",
      "Loss = 0.011585717089474201\n",
      "Loss = 0.011347725987434387\n",
      "Loss = 0.01111463364213705\n",
      "Loss = 0.010886342264711857\n",
      "Loss = 0.010662714950740337\n",
      "Loss = 0.010443695820868015\n",
      "Loss = 0.010229186154901981\n",
      "Loss = 0.010019059292972088\n",
      "Loss = 0.009813262149691582\n",
      "Loss = 0.009611707180738449\n",
      "Loss = 0.009414264000952244\n",
      "Loss = 0.009220900945365429\n",
      "Loss = 0.009031484834849834\n",
      "Loss = 0.008845989592373371\n",
      "Loss = 0.008664288558065891\n",
      "Loss = 0.008486318401992321\n",
      "Loss = 0.008311992511153221\n",
      "Loss = 0.008141257800161839\n",
      "Loss = 0.007974029518663883\n",
      "Loss = 0.007810238748788834\n",
      "Loss = 0.007649811450392008\n",
      "Loss = 0.007492693606764078\n",
      "Loss = 0.0073387804441154\n",
      "Loss = 0.007188031449913979\n",
      "Loss = 0.007040391210466623\n",
      "Loss = 0.006895780563354492\n",
      "Loss = 0.006754130590707064\n",
      "Loss = 0.006615402642637491\n",
      "Loss = 0.006479519885033369\n",
      "Loss = 0.0063464161939918995\n",
      "Loss = 0.006216065492480993\n",
      "Loss = 0.0060883779078722\n",
      "Loss = 0.005963324103504419\n",
      "Loss = 0.005840835627168417\n",
      "Loss = 0.005720853805541992\n",
      "Loss = 0.005603337194770575\n",
      "Loss = 0.00548825366422534\n",
      "Loss = 0.005375513806939125\n",
      "Loss = 0.005265097599476576\n",
      "Loss = 0.005156954284757376\n",
      "Loss = 0.005051025189459324\n",
      "Loss = 0.004947266541421413\n",
      "Loss = 0.004845642950385809\n",
      "Loss = 0.004746116232126951\n",
      "Loss = 0.004648631904274225\n",
      "Loss = 0.004553148988634348\n",
      "Loss = 0.004459609743207693\n",
      "Loss = 0.004368005320429802\n",
      "Loss = 0.004278285428881645\n",
      "Loss = 0.004190404433757067\n",
      "Loss = 0.004104340448975563\n",
      "Loss = 0.004020024556666613\n",
      "Loss = 0.003937460016459227\n",
      "Loss = 0.003856572089716792\n",
      "Loss = 0.0037773645017296076\n",
      "Loss = 0.0036997676361352205\n",
      "Loss = 0.0036237735766917467\n",
      "Loss = 0.0035493336617946625\n",
      "Loss = 0.0034764332231134176\n",
      "Loss = 0.0034050196409225464\n",
      "Loss = 0.0033350849989801645\n",
      "Loss = 0.0032665710896253586\n",
      "Loss = 0.003199478844180703\n",
      "Loss = 0.0031337616965174675\n",
      "Loss = 0.0030693847220391035\n",
      "Loss = 0.0030063369777053595\n",
      "Loss = 0.002944585867226124\n",
      "Loss = 0.002884100191295147\n",
      "Loss = 0.002824857598170638\n",
      "Loss = 0.00276683340780437\n",
      "Loss = 0.002710003172978759\n",
      "Loss = 0.0026543450076133013\n",
      "Loss = 0.0025998149067163467\n",
      "Loss = 0.002546415664255619\n",
      "Loss = 0.002494109096005559\n",
      "Loss = 0.0024428756441920996\n",
      "Loss = 0.002392701106145978\n",
      "Loss = 0.0023435503244400024\n",
      "Loss = 0.002295413985848427\n",
      "Loss = 0.0022482688073068857\n",
      "Loss = 0.002202087314799428\n",
      "Loss = 0.0021568534430116415\n",
      "Loss = 0.0021125527564436197\n",
      "Loss = 0.002069158013910055\n",
      "Loss = 0.002026649657636881\n",
      "Loss = 0.001985022099688649\n",
      "Loss = 0.0019442547345533967\n",
      "Loss = 0.0019043105421587825\n",
      "Loss = 0.001865197904407978\n",
      "Loss = 0.0018268871353939176\n",
      "Loss = 0.0017893561162054539\n",
      "Loss = 0.0017526020528748631\n",
      "Loss = 0.0017166092293336987\n",
      "Loss = 0.0016813477268442512\n",
      "Loss = 0.0016468069516122341\n",
      "Loss = 0.001612977939657867\n",
      "Loss = 0.0015798500971868634\n",
      "Loss = 0.0015474017709493637\n",
      "Loss = 0.0015156170120462775\n",
      "Loss = 0.0014844877878203988\n",
      "Loss = 0.0014539944240823388\n",
      "Loss = 0.0014241263270378113\n",
      "Loss = 0.001394878257997334\n",
      "Loss = 0.0013662218116223812\n",
      "Loss = 0.001338159549050033\n",
      "Loss = 0.0013106726109981537\n",
      "Loss = 0.0012837533140555024\n",
      "Loss = 0.0012573788408190012\n",
      "Loss = 0.001231550588272512\n",
      "Loss = 0.0012062526075169444\n",
      "Loss = 0.0011814808240160346\n",
      "Loss = 0.001157207414507866\n",
      "Loss = 0.0011334418086335063\n",
      "Loss = 0.0011101614218205214\n",
      "Loss = 0.0010873550781980157\n",
      "Loss = 0.0010650157928466797\n",
      "Loss = 0.001043142518028617\n",
      "Loss = 0.0010217168601229787\n",
      "Loss = 0.001000728807412088\n",
      "Loss = 0.0009801724227145314\n",
      "Loss = 0.0009600383345969021\n",
      "Loss = 0.0009403217118233442\n",
      "Loss = 0.000921002880204469\n",
      "Loss = 0.0009020839934237301\n",
      "Loss = 0.00088355882326141\n",
      "Loss = 0.0008654075209051371\n",
      "Loss = 0.0008476358489133418\n",
      "Loss = 0.0008302216301672161\n",
      "Loss = 0.0008131720242090523\n",
      "Loss = 0.0007964647375047207\n",
      "Loss = 0.0007801094907335937\n",
      "Loss = 0.000764079624786973\n",
      "Loss = 0.0007483895751647651\n",
      "Loss = 0.0007330130902118981\n",
      "Loss = 0.0007179551175795496\n",
      "Loss = 0.0007032111170701683\n",
      "Loss = 0.0006887638010084629\n",
      "Loss = 0.0006746212020516396\n",
      "Loss = 0.0006607613177038729\n",
      "Loss = 0.0006471884553320706\n",
      "Loss = 0.0006338975508697331\n",
      "Loss = 0.0006208776612766087\n",
      "Loss = 0.0006081206374801695\n",
      "Loss = 0.0005956299719400704\n",
      "Loss = 0.0005833960603922606\n",
      "Loss = 0.0005714111612178385\n",
      "Loss = 0.0005596763221547008\n",
      "Loss = 0.000548178271856159\n",
      "Loss = 0.0005369180580601096\n",
      "Loss = 0.0005258895107544959\n",
      "Loss = 0.0005150903016328812\n",
      "Loss = 0.0005045097204856575\n",
      "Loss = 0.0004941456136293709\n",
      "Loss = 0.0004839971661567688\n",
      "Loss = 0.00047405471559613943\n",
      "Loss = 0.0004643179418053478\n",
      "Loss = 0.0004547812568489462\n",
      "Loss = 0.00044543869444169104\n",
      "Loss = 0.0004362908657640219\n",
      "Loss = 0.00042732746805995703\n",
      "Loss = 0.0004185505968052894\n",
      "Loss = 0.0004099518118891865\n",
      "Loss = 0.000401531026000157\n",
      "Loss = 0.0003932836407329887\n",
      "Loss = 0.0003852063964586705\n",
      "Loss = 0.00037729289033450186\n",
      "Loss = 0.000369540968677029\n",
      "Loss = 0.00036195144639350474\n",
      "Loss = 0.00035451652365736663\n",
      "Loss = 0.0003472340467851609\n",
      "Loss = 0.0003401029680389911\n",
      "Loss = 0.0003331173211336136\n",
      "Loss = 0.0003262764948885888\n",
      "Loss = 0.0003195752506144345\n",
      "Loss = 0.0003130089899059385\n",
      "Loss = 0.0003065798955503851\n",
      "Loss = 0.0003002831363119185\n",
      "Loss = 0.00029411687864921987\n",
      "Loss = 0.0002880726824514568\n",
      "Loss = 0.0002821573580149561\n",
      "Loss = 0.0002763600496109575\n",
      "Loss = 0.00027068270719610155\n",
      "Loss = 0.0002651230606716126\n",
      "Loss = 0.00025967732653953135\n",
      "Loss = 0.0002543448063079268\n",
      "Loss = 0.0002491207851562649\n",
      "Loss = 0.00024400393886025995\n",
      "Loss = 0.00023899174993857741\n",
      "Loss = 0.00023408274864777923\n",
      "Loss = 0.00022927310783416033\n",
      "Loss = 0.0002245658979518339\n",
      "Loss = 0.00021995301358401775\n",
      "Loss = 0.00021543476032093167\n",
      "Loss = 0.0002110076165990904\n",
      "Loss = 0.00020667373610194772\n",
      "Loss = 0.00020242999016772956\n",
      "Loss = 0.0001982726389542222\n",
      "Loss = 0.00019420032913330942\n",
      "Loss = 0.0001902112999232486\n",
      "Loss = 0.00018630462000146508\n",
      "Loss = 0.00018247614207211882\n",
      "Loss = 0.00017872831085696816\n",
      "Loss = 0.0001750575756886974\n",
      "Loss = 0.00017146149184554815\n",
      "Loss = 0.00016793976828921586\n",
      "Loss = 0.00016449119721073657\n",
      "Loss = 0.00016111198056023568\n",
      "Loss = 0.00015780086687300354\n",
      "Loss = 0.00015456088294740766\n",
      "Loss = 0.00015138484013732523\n",
      "Loss = 0.0001482756488258019\n",
      "Loss = 0.0001452309516025707\n",
      "Loss = 0.0001422483182977885\n",
      "Loss = 0.00013932616275269538\n",
      "Loss = 0.0001364647614536807\n",
      "Loss = 0.0001336628192802891\n",
      "Loss = 0.00013091499567963183\n",
      "Loss = 0.0001282260927837342\n",
      "Loss = 0.00012559385504573584\n",
      "Loss = 0.0001230124180437997\n",
      "Loss = 0.00012048624193994328\n",
      "Loss = 0.00011801291111623868\n",
      "Loss = 0.00011558912956388667\n",
      "Loss = 0.00011321436613798141\n",
      "Loss = 0.0001108876895159483\n",
      "Loss = 0.00010861121700145304\n",
      "Loss = 0.00010637941886670887\n",
      "Loss = 0.00010419543832540512\n",
      "Loss = 0.00010205432045040652\n",
      "Loss = 9.995821164920926e-05\n",
      "Loss = 9.790417971089482e-05\n",
      "Loss = 9.589432738721371e-05\n",
      "Loss = 9.392443462274969e-05\n",
      "Loss = 9.19950834941119e-05\n",
      "tensor([[18.9720]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Prepare data\n",
    "xs = torch.tensor([[-1.0], [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
    "ys = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float32)\n",
    "\n",
    "# Training loop\n",
    "for _ in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(xs)\n",
    "    loss = criterion(outputs, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Loss = \" + str(loss.item()))\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    prediction = model(torch.tensor([[10.0]], dtype=torch.float32))\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQMjYiLzcr0P",
    "outputId": "991a17a7-c2ff-427b-ccee-7a959431a97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[1.9959443]]\n",
      "Bias: [-0.98742574]\n"
     ]
    }
   ],
   "source": [
    "# Access the first (and only) layer in the sequential model\n",
    "layer = model[0]\n",
    "\n",
    "# Get weights and bias\n",
    "weights = layer.weight.data.numpy()\n",
    "bias = layer.bias.data.numpy()\n",
    "\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
