{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrLt-C4PRV_f",
    "outputId": "93b5119e-505d-4ab5-a3bb-26803d9b517f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu130\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce GTX 1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/5A60AFFC60AFDCCF/PyCode/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1070 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.5) - (12.0)\n",
      "    \n",
      "  queued_call()\n",
      "/mnt/5A60AFFC60AFDCCF/PyCode/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  queued_call()\n",
      "/mnt/5A60AFFC60AFDCCF/PyCode/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "NVIDIA GeForce GTX 1070 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_75 sm_80 sm_86 sm_90 sm_100 sm_120 compute_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  queued_call()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (NVIDIA GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It4yTLaRao7o",
    "outputId": "896ad986-b4bd-4376-ef3d-9575aa9cd807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 13.781722068786621\n",
      "Loss = 11.350892066955566\n",
      "Loss = 9.427998542785645\n",
      "Loss = 7.904935836791992\n",
      "Loss = 6.696650981903076\n",
      "Loss = 5.736223220825195\n",
      "Loss = 4.970999717712402\n",
      "Loss = 4.359550952911377\n",
      "Loss = 3.869279146194458\n",
      "Loss = 3.4745304584503174\n",
      "Loss = 3.1551218032836914\n",
      "Loss = 2.8951680660247803\n",
      "Loss = 2.6821680068969727\n",
      "Loss = 2.5062835216522217\n",
      "Loss = 2.3597700595855713\n",
      "Loss = 2.23653244972229\n",
      "Loss = 2.1317691802978516\n",
      "Loss = 2.0417025089263916\n",
      "Loss = 1.963354468345642\n",
      "Loss = 1.89437997341156\n",
      "Loss = 1.8329311609268188\n",
      "Loss = 1.777550220489502\n",
      "Loss = 1.7270880937576294\n",
      "Loss = 1.6806378364562988\n",
      "Loss = 1.6374813318252563\n",
      "Loss = 1.5970534086227417\n",
      "Loss = 1.5589042901992798\n",
      "Loss = 1.522678256034851\n",
      "Loss = 1.4880932569503784\n",
      "Loss = 1.45492422580719\n",
      "Loss = 1.4229912757873535\n",
      "Loss = 1.3921513557434082\n",
      "Loss = 1.3622881174087524\n",
      "Loss = 1.3333085775375366\n",
      "Loss = 1.305137276649475\n",
      "Loss = 1.2777115106582642\n",
      "Loss = 1.2509809732437134\n",
      "Loss = 1.2249029874801636\n",
      "Loss = 1.1994422674179077\n",
      "Loss = 1.1745685338974\n",
      "Loss = 1.1502560377120972\n",
      "Loss = 1.126482605934143\n",
      "Loss = 1.1032288074493408\n",
      "Loss = 1.0804773569107056\n",
      "Loss = 1.058212399482727\n",
      "Loss = 1.0364198684692383\n",
      "Loss = 1.0150870084762573\n",
      "Loss = 0.9942017197608948\n",
      "Loss = 0.9737531542778015\n",
      "Loss = 0.953730046749115\n",
      "Loss = 0.9341228008270264\n",
      "Loss = 0.9149220585823059\n",
      "Loss = 0.896118700504303\n",
      "Loss = 0.8777036070823669\n",
      "Loss = 0.8596685528755188\n",
      "Loss = 0.8420054316520691\n",
      "Loss = 0.8247060775756836\n",
      "Loss = 0.8077628016471863\n",
      "Loss = 0.7911684513092041\n",
      "Loss = 0.7749154567718506\n",
      "Loss = 0.7589966654777527\n",
      "Loss = 0.7434051632881165\n",
      "Loss = 0.7281342148780823\n",
      "Loss = 0.7131772041320801\n",
      "Loss = 0.6985275149345398\n",
      "Loss = 0.6841788291931152\n",
      "Loss = 0.6701250076293945\n",
      "Loss = 0.6563599705696106\n",
      "Loss = 0.6428776383399963\n",
      "Loss = 0.6296724081039429\n",
      "Loss = 0.616738498210907\n",
      "Loss = 0.6040701866149902\n",
      "Loss = 0.5916620492935181\n",
      "Loss = 0.579508900642395\n",
      "Loss = 0.5676053762435913\n",
      "Loss = 0.5559463500976562\n",
      "Loss = 0.5445268750190735\n",
      "Loss = 0.5333418846130371\n",
      "Loss = 0.5223867297172546\n",
      "Loss = 0.5116565227508545\n",
      "Loss = 0.5011468529701233\n",
      "Loss = 0.490852952003479\n",
      "Loss = 0.4807705581188202\n",
      "Loss = 0.4708952009677887\n",
      "Loss = 0.4612227976322174\n",
      "Loss = 0.4517488479614258\n",
      "Loss = 0.4424697160720825\n",
      "Loss = 0.433381050825119\n",
      "Loss = 0.424479216337204\n",
      "Loss = 0.4157601594924927\n",
      "Loss = 0.4072202146053314\n",
      "Loss = 0.398855596780777\n",
      "Loss = 0.39066281914711\n",
      "Loss = 0.38263845443725586\n",
      "Loss = 0.37477874755859375\n",
      "Loss = 0.36708056926727295\n",
      "Loss = 0.35954055190086365\n",
      "Loss = 0.3521554172039032\n",
      "Loss = 0.34492191672325134\n",
      "Loss = 0.33783695101737976\n",
      "Loss = 0.33089759945869446\n",
      "Loss = 0.3241007626056671\n",
      "Loss = 0.31744351983070374\n",
      "Loss = 0.3109230101108551\n",
      "Loss = 0.3045364320278168\n",
      "Loss = 0.29828110337257385\n",
      "Loss = 0.2921541631221771\n",
      "Loss = 0.2861531674861908\n",
      "Loss = 0.2802753746509552\n",
      "Loss = 0.27451834082603455\n",
      "Loss = 0.26887956261634827\n",
      "Loss = 0.26335662603378296\n",
      "Loss = 0.2579471170902252\n",
      "Loss = 0.25264880061149597\n",
      "Loss = 0.24745917320251465\n",
      "Loss = 0.2423762083053589\n",
      "Loss = 0.23739773035049438\n",
      "Loss = 0.2325213998556137\n",
      "Loss = 0.22774524986743927\n",
      "Loss = 0.2230672687292099\n",
      "Loss = 0.2184852957725525\n",
      "Loss = 0.213997483253479\n",
      "Loss = 0.20960180461406708\n",
      "Loss = 0.20529650151729584\n",
      "Loss = 0.2010796070098877\n",
      "Loss = 0.19694925844669342\n",
      "Loss = 0.1929038017988205\n",
      "Loss = 0.18894146382808685\n",
      "Loss = 0.18506044149398804\n",
      "Loss = 0.18125922977924347\n",
      "Loss = 0.1775360256433487\n",
      "Loss = 0.17388929426670074\n",
      "Loss = 0.17031757533550262\n",
      "Loss = 0.16681914031505585\n",
      "Loss = 0.1633925437927246\n",
      "Loss = 0.1600363403558731\n",
      "Loss = 0.15674911439418793\n",
      "Loss = 0.15352937579154968\n",
      "Loss = 0.15037579834461212\n",
      "Loss = 0.14728699624538422\n",
      "Loss = 0.1442616581916809\n",
      "Loss = 0.14129841327667236\n",
      "Loss = 0.13839605450630188\n",
      "Loss = 0.13555331528186798\n",
      "Loss = 0.13276894390583038\n",
      "Loss = 0.13004179298877716\n",
      "Loss = 0.1273706704378128\n",
      "Loss = 0.12475442886352539\n",
      "Loss = 0.12219187617301941\n",
      "Loss = 0.11968200653791428\n",
      "Loss = 0.11722365021705627\n",
      "Loss = 0.11481577903032303\n",
      "Loss = 0.11245735734701157\n",
      "Loss = 0.11014745384454727\n",
      "Loss = 0.10788492113351822\n",
      "Loss = 0.10566892474889755\n",
      "Loss = 0.10349839925765991\n",
      "Loss = 0.10137245059013367\n",
      "Loss = 0.09929021447896957\n",
      "Loss = 0.09725070744752884\n",
      "Loss = 0.09525316208600998\n",
      "Loss = 0.093296580016613\n",
      "Loss = 0.09138020128011703\n",
      "Loss = 0.08950316905975342\n",
      "Loss = 0.08766476064920425\n",
      "Loss = 0.08586405962705612\n",
      "Loss = 0.08410035818815231\n",
      "Loss = 0.08237291127443314\n",
      "Loss = 0.08068087697029114\n",
      "Loss = 0.07902365177869797\n",
      "Loss = 0.07740046083927155\n",
      "Loss = 0.07581058889627457\n",
      "Loss = 0.0742533951997757\n",
      "Loss = 0.07272820174694061\n",
      "Loss = 0.071234330534935\n",
      "Loss = 0.06977111846208572\n",
      "Loss = 0.06833796203136444\n",
      "Loss = 0.0669342502951622\n",
      "Loss = 0.06555937975645065\n",
      "Loss = 0.06421271711587906\n",
      "Loss = 0.06289375573396683\n",
      "Loss = 0.06160189211368561\n",
      "Loss = 0.06033654883503914\n",
      "Loss = 0.05909719690680504\n",
      "Loss = 0.057883333414793015\n",
      "Loss = 0.05669436976313591\n",
      "Loss = 0.055529847741127014\n",
      "Loss = 0.05438922345638275\n",
      "Loss = 0.05327200889587402\n",
      "Loss = 0.05217777565121651\n",
      "Loss = 0.05110601708292961\n",
      "Loss = 0.05005628243088722\n",
      "Loss = 0.04902809485793114\n",
      "Loss = 0.04802100732922554\n",
      "Loss = 0.04703463241457939\n",
      "Loss = 0.04606851562857628\n",
      "Loss = 0.04512220621109009\n",
      "Loss = 0.04419538378715515\n",
      "Loss = 0.04328760504722595\n",
      "Loss = 0.04239845648407936\n",
      "Loss = 0.04152756556868553\n",
      "Loss = 0.040674563497304916\n",
      "Loss = 0.039839088916778564\n",
      "Loss = 0.039020758122205734\n",
      "Loss = 0.03821923956274986\n",
      "Loss = 0.037434183061122894\n",
      "Loss = 0.036665260791778564\n",
      "Loss = 0.0359121598303318\n",
      "Loss = 0.03517448157072067\n",
      "Loss = 0.034451961517333984\n",
      "Loss = 0.03374430909752846\n",
      "Loss = 0.03305119648575783\n",
      "Loss = 0.03237229958176613\n",
      "Loss = 0.03170735388994217\n",
      "Loss = 0.031056063249707222\n",
      "Loss = 0.030418135225772858\n",
      "Loss = 0.02979334443807602\n",
      "Loss = 0.029181376099586487\n",
      "Loss = 0.028581969439983368\n",
      "Loss = 0.02799486555159092\n",
      "Loss = 0.02741982229053974\n",
      "Loss = 0.026856621727347374\n",
      "Loss = 0.02630496211349964\n",
      "Loss = 0.025764619931578636\n",
      "Loss = 0.02523542381823063\n",
      "Loss = 0.024717064574360847\n",
      "Loss = 0.02420937269926071\n",
      "Loss = 0.023712093010544777\n",
      "Loss = 0.02322501689195633\n",
      "Loss = 0.022747984156012535\n",
      "Loss = 0.022280709818005562\n",
      "Loss = 0.021823065355420113\n",
      "Loss = 0.021374784409999847\n",
      "Loss = 0.020935727283358574\n",
      "Loss = 0.020505700260400772\n",
      "Loss = 0.02008449286222458\n",
      "Loss = 0.01967196725308895\n",
      "Loss = 0.019267892464995384\n",
      "Loss = 0.018872112035751343\n",
      "Loss = 0.01848444901406765\n",
      "Loss = 0.018104765564203262\n",
      "Loss = 0.017732886597514153\n",
      "Loss = 0.017368657514452934\n",
      "Loss = 0.01701188273727894\n",
      "Loss = 0.01666245423257351\n",
      "Loss = 0.01632019877433777\n",
      "Loss = 0.015984976664185524\n",
      "Loss = 0.01565663330256939\n",
      "Loss = 0.01533504854887724\n",
      "Loss = 0.015020049177110195\n",
      "Loss = 0.01471153274178505\n",
      "Loss = 0.014409355819225311\n",
      "Loss = 0.014113376848399639\n",
      "Loss = 0.013823457062244415\n",
      "Loss = 0.013539522886276245\n",
      "Loss = 0.013261423446238041\n",
      "Loss = 0.012989025563001633\n",
      "Loss = 0.01272222027182579\n",
      "Loss = 0.012460902333259583\n",
      "Loss = 0.012204955331981182\n",
      "Loss = 0.011954248882830143\n",
      "Loss = 0.011708710342645645\n",
      "Loss = 0.011468198150396347\n",
      "Loss = 0.011232640594244003\n",
      "Loss = 0.011001922190189362\n",
      "Loss = 0.010775931179523468\n",
      "Loss = 0.01055460050702095\n",
      "Loss = 0.010337790474295616\n",
      "Loss = 0.010125444270670414\n",
      "Loss = 0.009917466901242733\n",
      "Loss = 0.009713747538626194\n",
      "Loss = 0.00951421819627285\n",
      "Loss = 0.009318792261183262\n",
      "Loss = 0.009127382189035416\n",
      "Loss = 0.00893990695476532\n",
      "Loss = 0.008756273426115513\n",
      "Loss = 0.00857642199844122\n",
      "Loss = 0.00840024184435606\n",
      "Loss = 0.008227713406085968\n",
      "Loss = 0.008058706298470497\n",
      "Loss = 0.00789317861199379\n",
      "Loss = 0.007731049787253141\n",
      "Loss = 0.007572254631668329\n",
      "Loss = 0.007416705135256052\n",
      "Loss = 0.0072643631137907505\n",
      "Loss = 0.007115155458450317\n",
      "Loss = 0.0069690062664449215\n",
      "Loss = 0.006825852673500776\n",
      "Loss = 0.006685640197247267\n",
      "Loss = 0.0065483208745718\n",
      "Loss = 0.006413815077394247\n",
      "Loss = 0.006282068323343992\n",
      "Loss = 0.006153029855340719\n",
      "Loss = 0.0060266475193202496\n",
      "Loss = 0.005902854725718498\n",
      "Loss = 0.005781601648777723\n",
      "Loss = 0.005662855226546526\n",
      "Loss = 0.005546537693589926\n",
      "Loss = 0.005432611797004938\n",
      "Loss = 0.0053210132755339146\n",
      "Loss = 0.005211725365370512\n",
      "Loss = 0.005104669835418463\n",
      "Loss = 0.004999817814677954\n",
      "Loss = 0.004897131584584713\n",
      "Loss = 0.0047965338453650475\n",
      "Loss = 0.004698006436228752\n",
      "Loss = 0.004601516295224428\n",
      "Loss = 0.004506995435804129\n",
      "Loss = 0.004414412658661604\n",
      "Loss = 0.004323744680732489\n",
      "Loss = 0.004234937485307455\n",
      "Loss = 0.004147942643612623\n",
      "Loss = 0.004062735941261053\n",
      "Loss = 0.003979286644607782\n",
      "Loss = 0.0038975521456450224\n",
      "Loss = 0.0038174958899617195\n",
      "Loss = 0.0037390822544693947\n",
      "Loss = 0.0036622730549424887\n",
      "Loss = 0.0035870468709617853\n",
      "Loss = 0.0035133713390678167\n",
      "Loss = 0.0034412106033414602\n",
      "Loss = 0.0033705260138958693\n",
      "Loss = 0.0033012942876666784\n",
      "Loss = 0.0032334811985492706\n",
      "Loss = 0.00316705834120512\n",
      "Loss = 0.003102012909948826\n",
      "Loss = 0.003038291120901704\n",
      "Loss = 0.0029758901800960302\n",
      "Loss = 0.0029147567693144083\n",
      "Loss = 0.002854889025911689\n",
      "Loss = 0.002796249696984887\n",
      "Loss = 0.0027388085145503283\n",
      "Loss = 0.002682552905753255\n",
      "Loss = 0.0026274581905454397\n",
      "Loss = 0.002573487814515829\n",
      "Loss = 0.0025206217542290688\n",
      "Loss = 0.0024688479024916887\n",
      "Loss = 0.002418138086795807\n",
      "Loss = 0.002368466230109334\n",
      "Loss = 0.002319812308996916\n",
      "Loss = 0.002272160956636071\n",
      "Loss = 0.002225490752607584\n",
      "Loss = 0.0021797816734761\n",
      "Loss = 0.002135006943717599\n",
      "Loss = 0.00209115375764668\n",
      "Loss = 0.00204819836653769\n",
      "Loss = 0.0020061268005520105\n",
      "Loss = 0.001964918337762356\n",
      "Loss = 0.0019245640141889453\n",
      "Loss = 0.0018850298365578055\n",
      "Loss = 0.0018463080050423741\n",
      "Loss = 0.001808387809433043\n",
      "Loss = 0.001771234441548586\n",
      "Loss = 0.0017348570981994271\n",
      "Loss = 0.0016992202727124095\n",
      "Loss = 0.0016643167473375797\n",
      "Loss = 0.0016301298746839166\n",
      "Loss = 0.00159664626698941\n",
      "Loss = 0.0015638559125363827\n",
      "Loss = 0.0015317336656153202\n",
      "Loss = 0.001500271842814982\n",
      "Loss = 0.0014694547280669212\n",
      "Loss = 0.001439272309653461\n",
      "Loss = 0.0014097091043367982\n",
      "Loss = 0.001380752306431532\n",
      "Loss = 0.0013523910893127322\n",
      "Loss = 0.0013246118323877454\n",
      "Loss = 0.0012974102282896638\n",
      "Loss = 0.0012707581045106053\n",
      "Loss = 0.001244656159542501\n",
      "Loss = 0.0012190932175144553\n",
      "Loss = 0.001194048672914505\n",
      "Loss = 0.0011695193825289607\n",
      "Loss = 0.0011454980121925473\n",
      "Loss = 0.0011219698935747147\n",
      "Loss = 0.0010989252477884293\n",
      "Loss = 0.0010763559257611632\n",
      "Loss = 0.0010542479576542974\n",
      "Loss = 0.001032593077979982\n",
      "Loss = 0.001011380460113287\n",
      "Loss = 0.0009906028863042593\n",
      "Loss = 0.0009702544193714857\n",
      "Loss = 0.0009503252804279327\n",
      "Loss = 0.0009308078442700207\n",
      "Loss = 0.0009116846485994756\n",
      "Loss = 0.0008929605246521533\n",
      "Loss = 0.0008746183593757451\n",
      "Loss = 0.0008566495962440968\n",
      "Loss = 0.0008390545845031738\n",
      "Loss = 0.0008218222646974027\n",
      "Loss = 0.0008049404714256525\n",
      "Loss = 0.0007884094957262278\n",
      "Loss = 0.0007722145528532565\n",
      "Loss = 0.0007563524413853884\n",
      "Loss = 0.0007408135570585728\n",
      "Loss = 0.0007255952223204076\n",
      "Loss = 0.0007106938282959163\n",
      "Loss = 0.0006960949394851923\n",
      "Loss = 0.000681798963341862\n",
      "Loss = 0.0006677936762571335\n",
      "Loss = 0.0006540738977491856\n",
      "Loss = 0.0006406381144188344\n",
      "Loss = 0.000627483066637069\n",
      "Loss = 0.000614592048805207\n",
      "Loss = 0.0006019708816893399\n",
      "Loss = 0.0005896060029044747\n",
      "Loss = 0.0005774959572590888\n",
      "Loss = 0.0005656331777572632\n",
      "Loss = 0.0005540153943002224\n",
      "Loss = 0.0005426344578154385\n",
      "Loss = 0.0005314926966093481\n",
      "Loss = 0.0005205758498050272\n",
      "Loss = 0.0005098811234347522\n",
      "Loss = 0.000499408517498523\n",
      "Loss = 0.0004891511634923518\n",
      "Loss = 0.00047910245484672487\n",
      "Loss = 0.00046926343929953873\n",
      "Loss = 0.0004596219805534929\n",
      "Loss = 0.0004501828516367823\n",
      "Loss = 0.0004409344110172242\n",
      "Loss = 0.0004318762512411922\n",
      "Loss = 0.00042300732457078993\n",
      "Loss = 0.00041431569843553007\n",
      "Loss = 0.000405805156333372\n",
      "Loss = 0.0003974705468863249\n",
      "Loss = 0.0003893075045198202\n",
      "Loss = 0.0003813098883256316\n",
      "Loss = 0.00037347941542975605\n",
      "Loss = 0.0003658079949673265\n",
      "Loss = 0.0003582945792004466\n",
      "Loss = 0.00035093314363621175\n",
      "Loss = 0.00034372613299638033\n",
      "Loss = 0.0003366652817931026\n",
      "Loss = 0.0003297502116765827\n",
      "Loss = 0.0003229756548535079\n",
      "Loss = 0.00031634318293072283\n",
      "Loss = 0.000309845432639122\n",
      "Loss = 0.00030347853316925466\n",
      "Loss = 0.0002972447546198964\n",
      "Loss = 0.00029113798518665135\n",
      "Loss = 0.0002851576718967408\n",
      "Loss = 0.0002793016319628805\n",
      "Loss = 0.0002735640446189791\n",
      "Loss = 0.0002679445606190711\n",
      "Loss = 0.0002624398039188236\n",
      "Loss = 0.0002570507931523025\n",
      "Loss = 0.00025177220231853426\n",
      "Loss = 0.0002465996949467808\n",
      "Loss = 0.00024153558479156345\n",
      "Loss = 0.00023657306155655533\n",
      "Loss = 0.00023171295470092446\n",
      "Loss = 0.00022695619554724544\n",
      "Loss = 0.00022229451860766858\n",
      "Loss = 0.0002177265560021624\n",
      "Loss = 0.00021325501438695937\n",
      "Loss = 0.00020887616847176105\n",
      "Loss = 0.00020458428480196744\n",
      "Loss = 0.00020038190996274352\n",
      "Loss = 0.00019626553694251925\n",
      "Loss = 0.00019223614071961492\n",
      "Loss = 0.00018828657630365342\n",
      "Loss = 0.00018441940483171493\n",
      "Loss = 0.00018062932940665632\n",
      "Loss = 0.0001769201480783522\n",
      "Loss = 0.0001732856617309153\n",
      "Loss = 0.0001697278203209862\n",
      "Loss = 0.00016624038107693195\n",
      "Loss = 0.000162825221195817\n",
      "Loss = 0.0001594804198248312\n",
      "Loss = 0.00015620666090399027\n",
      "Loss = 0.0001529972068965435\n",
      "Loss = 0.00014985589950811118\n",
      "Loss = 0.00014677680155728012\n",
      "Loss = 0.00014376096078194678\n",
      "Loss = 0.00014080751861911267\n",
      "Loss = 0.00013791579112876207\n",
      "Loss = 0.00013508227129932493\n",
      "Loss = 0.00013230738113634288\n",
      "Loss = 0.00012959026207681745\n",
      "Loss = 0.00012692790187429637\n",
      "Loss = 0.0001243199803866446\n",
      "Loss = 0.00012176796008134261\n",
      "Loss = 0.00011926645674975589\n",
      "Loss = 0.00011681588512146845\n",
      "Loss = 0.00011441615788498893\n",
      "Loss = 0.000112066489236895\n",
      "Loss = 0.0001097647545975633\n",
      "Loss = 0.00010750791989266872\n",
      "Loss = 0.00010530096915317699\n",
      "Loss = 0.00010313715756637976\n",
      "Loss = 0.00010101931547978893\n",
      "Loss = 9.894380491459742e-05\n",
      "Loss = 9.691235754871741e-05\n",
      "Loss = 9.492075332673267e-05\n",
      "Loss = 9.297162614529952e-05\n",
      "Loss = 9.106270590564236e-05\n",
      "Loss = 8.919238462112844e-05\n",
      "Loss = 8.73608878464438e-05\n",
      "Loss = 8.556668763048947e-05\n",
      "Loss = 8.380823419429362e-05\n",
      "tensor([[18.9733]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(nn.Linear(1, 1))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Prepare data\n",
    "xs = torch.tensor([[-1.0], [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
    "ys = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float32)\n",
    "\n",
    "# Training loop\n",
    "for _ in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(xs)\n",
    "    loss = criterion(outputs, ys)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Loss = \" + str(loss.item()))\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    prediction = model(torch.tensor([[10.0]], dtype=torch.float32))\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQMjYiLzcr0P",
    "outputId": "991a17a7-c2ff-427b-ccee-7a959431a97b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[1.9970648]]\n",
      "Bias: [-0.9908999]\n"
     ]
    }
   ],
   "source": [
    "# Access the first (and only) layer in the sequential model\n",
    "layer = model[0]\n",
    "\n",
    "# Get weights and bias\n",
    "weights = layer.weight.data.numpy()\n",
    "bias = layer.bias.data.numpy()\n",
    "\n",
    "print(\"Weights:\", weights)\n",
    "print(\"Bias:\", bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
